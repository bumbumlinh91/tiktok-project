{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e67a91",
   "metadata": {},
   "source": [
    "\n",
    "# TikTok Claim vs Opinion Detection\n",
    "\n",
    "**Goal.** Classify a TikTok caption/transcript as **Claim (1)** or **Opinion (0)** to support moderation & fact-checking.  \n",
    "**Primary KPI.** Recall (Claim) with balanced F1 across classes.  \n",
    "**Scope.** Text only (caption/transcript). No audio/video features in this iteration.  \n",
    "**Assumptions.** Labels were annotated using guideline v1.2 (below).  \n",
    "**Constraints.** Lightweight model for near-real-time screening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment & Reproducibility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, \\\n",
    "recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "data_path = \"data/tiktok_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6bb9d0",
   "metadata": {},
   "source": [
    "# **Understand the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1456c80",
   "metadata": {},
   "source": [
    "## **Inspect the data**\n",
    "\n",
    "View and inspect summary information about the dataframe by **coding the following:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93422609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 10 rows of dataframe\n",
    "data = pd.read_csv(data_path)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9969b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the data\n",
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927487f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary info\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a645d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc64b6",
   "metadata": {},
   "source": [
    "**from the first 10 rows of df:** The dataframe contains a collection of categorical, text, and numerical data. Each row represents a distinct TikTok video that presents either a claim or an opinion and the accompanying metadata about that video.\n",
    "\n",
    "**from the summary info:** missing values including claim status, the video transcripton, and all of the count variables.\n",
    "\n",
    "**from summary statistic:** many of the count variables seem to have outliers at the high end of the distribution. They have very large standard deviations and maximum values that are very high compared to their quartile values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d6db1",
   "metadata": {},
   "source": [
    "## **Investigate the variables**\n",
    "\n",
    "Investigating the variables more closely to better understand them.\n",
    "\n",
    "The ultimate objective is to use machine learning to classify videos as either claims or opinions. A good first step towards understanding the data might therefore be examining the `claim_status` variable. Begin by determining how many videos there are for each different claim status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different claim status counts\n",
    "\n",
    "data['claim_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average view count of videos with \"claim\" status\n",
    "\n",
    "claims = data[data['claim_status'] == 'claim']\n",
    "print('Mean view count claims:', claims['video_view_count'].mean())\n",
    "print('Median view count claims:', claims['video_view_count'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31026c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average view count of videos with \"opinion\" status\n",
    "\n",
    "opinions = data[data['claim_status'] == 'opinion']\n",
    "print('Mean view count opinions:', opinions['video_view_count'].mean())\n",
    "print('Median view count opinions:', opinions['video_view_count'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402cbbdb",
   "metadata": {},
   "source": [
    "The mean and the median within each claim category are close to one another, but there is a vast discrepancy between view counts for videos labeled as claims and videos labeled as opinions.\n",
    "\n",
    "Next, examine trends associated with the ban status of the author.\n",
    "\n",
    "Use `groupby()` to calculate how many videos there are for each combination of categories of claim status and author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each group combination of claim status and author ban status\n",
    "\n",
    "data.groupby(['claim_status', 'author_ban_status']).count()[['#']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d51cab",
   "metadata": {},
   "source": [
    "more claim videos with banned authors than there are opinion videos with banned authors. This may be due to:\n",
    "* Claim videos are more strictly policed than opinion videos\n",
    "* Authors must comply with a stricter set of rules if they post a claim than if they post an opinion\n",
    "\n",
    "Also, it should be noted that there's no way of knowing if claim videos are inherently more likely than opinion videos to result in author bans, or if authors who post claim videos are more likely to post videos that violate terms of service.\n",
    "\n",
    "Finally, while you can use this data to draw conclusions about banned/active authors, you cannot draw conclusions about banned videos. There's no way of determining whether a particular video _caused_ the ban, and banned authors could have posted videos that complied with the terms of service.\n",
    "\n",
    "\n",
    "Continue investigating engagement levels, now focusing on `author_ban_status`.\n",
    "\n",
    "Calculate the median video share count of each author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the median video share count of each author ban status\n",
    "\n",
    "data.groupby(['author_ban_status']).median(numeric_only=True)[\n",
    "    ['video_share_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column='video_share_count', by='author_ban_status')\n",
    "plt.title('Shares by Author Ban Status'); plt.suptitle(''); plt.xlabel(''); plt.ylabel('video_share_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedd51b",
   "metadata": {},
   "source": [
    "Banned authors have a median share count that's 33 times the median share count of active authors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa32edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.groupby(['author_ban_status']).agg(\n",
    "    {'video_view_count': ['count', 'mean', 'median'],\n",
    "     'video_like_count': ['count', 'mean', 'median'],\n",
    "     'video_share_count': ['count', 'mean', 'median']\n",
    "     })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52543e7",
   "metadata": {},
   "source": [
    "A few observations stand out:\n",
    "* Banned authors and those under review get far more views, likes, and shares than active authors.\n",
    "* In most groups, the mean is much greater than the median, which indicates that there are some videos with very high engagement counts.\n",
    "\n",
    "Now, create three new columns to help better understand engagement rates:\n",
    "* `likes_per_view`: represents the number of likes divided by the number of views for each video\n",
    "* `comments_per_view`: represents the number of comments divided by the number of views for each video\n",
    "* `shares_per_view`: represents the number of shares divided by the number of views for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a likes_per_view column\n",
    "data['likes_per_view'] = data['video_like_count'] / data['video_view_count']\n",
    "\n",
    "# Create a comments_per_view column\n",
    "data['comments_per_view'] = data['video_comment_count'] / data['video_view_count']\n",
    "\n",
    "# Create a shares_per_view column\n",
    "data['shares_per_view'] = data['video_share_count'] / data['video_view_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2260a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['claim_status', 'author_ban_status']).agg(\n",
    "    {'likes_per_view': ['count', 'mean', 'median'],\n",
    "     'comments_per_view': ['count', 'mean', 'median'],\n",
    "     'shares_per_view': ['count', 'mean', 'median']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eefb74",
   "metadata": {},
   "source": [
    "videos by banned authors and under review tend to get more views, likes, and shares than videos by non-banned authors. However, *when a video does get viewed*, its engagement rate is less related to author ban status and more related to its claim status.\n",
    "\n",
    "claim videos receive more engagement via comments and shares than opinion videos.\n",
    "\n",
    "for claim videos, banned authors have slightly higher likes/view and shares/view rates than active authors or those under review. However, for opinion videos, active authors and those under review both get higher engagement rates than banned authors in all categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ddc09",
   "metadata": {},
   "source": [
    "# **Build visualizations**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c8b7a",
   "metadata": {},
   "source": [
    "#### **video_duration_sec**\n",
    "\n",
    "Create a box plot to examine the spread of values in the `video_duration_sec` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defe28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_duration_sec')\n",
    "sns.boxplot(x=data['video_duration_sec']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce6a65",
   "metadata": {},
   "source": [
    "Create a histogram of the values in the `video_duration_sec` column to further explore the distribution of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_duration_sec'], bins=range(0,61,5))\n",
    "plt.title('Video duration histogram');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139afee",
   "metadata": {},
   "source": [
    "All videos are 5-60 seconds in length, and the distribution is uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7082acb",
   "metadata": {},
   "source": [
    "#### **video_view_count**\n",
    "\n",
    "Create a box plot to examine the spread of values in the `video_view_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to visualize distribution of `video_view_count`\n",
    "plt.figure(figsize=(5, 1))\n",
    "plt.title('video_view_count')\n",
    "sns.boxplot(x=data['video_view_count']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e9435",
   "metadata": {},
   "source": [
    "Create a histogram of the values in the `video_view_count` column to further explore the distribution of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_view_count'], bins=range(0,(10**6+1),10**5))\n",
    "plt.title('Video view count histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42bc14",
   "metadata": {},
   "source": [
    "This variable has a very uneven distribution, with more than half the videos receiving fewer than 100,000 views. Distribution of view counts > 100,000 views is uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b475fb4",
   "metadata": {},
   "source": [
    "#### **video_like_count**\n",
    "\n",
    "Create a box plot to examine the spread of values in the `video_like_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "plt.title('video_like_count')\n",
    "sns.boxplot(x=data['video_like_count']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666acf90",
   "metadata": {},
   "source": [
    "Create a histogram of the values in the `video_like_count` column to further explore the distribution of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38eb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "ax = sns.histplot(data['video_like_count'], bins=range(0,(7*10**5+1),10**5))\n",
    "labels = [0] + [str(i) + 'k' for i in range(100, 701, 100)]\n",
    "ax.set_xticks(range(0,7*10**5+1,10**5), labels=labels)\n",
    "plt.title('Video like count histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78814855",
   "metadata": {},
   "source": [
    "Similar to view count, there are far more videos with < 100,000 likes than there are videos with more. However, in this case, there is more of a taper, as the data skews right, with many videos at the upper extremity of like count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba7727",
   "metadata": {},
   "source": [
    "#### **video_comment_count**\n",
    "\n",
    "Create a box plot to examine the spread of values in the `video_comment_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_comment_count')\n",
    "sns.boxplot(x=data['video_comment_count']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c5dff",
   "metadata": {},
   "source": [
    "Create a histogram of the values in the `video_comment_count` column to further explore the distribution of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_comment_count'], bins=range(0,(3001),100))\n",
    "plt.title('Video comment count histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9daf2",
   "metadata": {},
   "source": [
    "Again, the vast majority of videos are grouped at the bottom of the range of values for video comment count. Most videos have fewer than 100 comments. The distribution is very right-skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa3957",
   "metadata": {},
   "source": [
    "#### **video_share_count**\n",
    "\n",
    "Create a box plot to examine the spread of values in the `video_share_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_share_count')\n",
    "sns.boxplot(x=data['video_share_count']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834ebf3",
   "metadata": {},
   "source": [
    "Create a histogram of the values in the `video_share_count` column to further explore the distribution of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_share_count'], bins=range(0,(270001),10000))\n",
    "plt.title('Video share count histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93356a75",
   "metadata": {},
   "source": [
    "The overwhelming majority of videos had fewer than 10,000 shares. The distribution is very skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c884e",
   "metadata": {},
   "source": [
    "#### **video_download_count**\n",
    "\n",
    "Create a box plot to examine the spread of values in the `video_download_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21085b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,1))\n",
    "plt.title('video_download_count')\n",
    "sns.boxplot(x=data['video_download_count']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5514c",
   "metadata": {},
   "source": [
    "Create a histogram of the values in the `video_download_count` column to further explore the distribution of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb046fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "sns.histplot(data['video_download_count'], bins=range(0,(15001),500))\n",
    "plt.title('Video download count histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32607ede",
   "metadata": {},
   "source": [
    "The majority of videos were downloaded fewer than 500 times, but some were downloaded over 12,000 times. Again, the data is very skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3a3b6",
   "metadata": {},
   "source": [
    "#### **Claim status by verification status**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fa0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(data=data,\n",
    "             x='claim_status',\n",
    "             hue='verified_status',\n",
    "             multiple='dodge',\n",
    "             shrink=0.9)\n",
    "plt.title('Claims by verification status histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943448e",
   "metadata": {},
   "source": [
    "There are far fewer verified users than unverified users, but if a user *is* verified, they are much more likely to post opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcaee13",
   "metadata": {},
   "source": [
    "#### **Claim status by author ban status**\n",
    "\n",
    "The previous part used a `groupby()` statement to examine the count of each claim status for each author ban status. Now, visualize it by histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8bde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,4))\n",
    "sns.histplot(data, x='claim_status', hue='author_ban_status',\n",
    "             multiple='dodge',\n",
    "             hue_order=['active', 'under review', 'banned'],\n",
    "             shrink=0.9,\n",
    "             palette={'active':'green', 'under review':'orange', 'banned':'red'},\n",
    "             alpha=0.5)\n",
    "plt.title('Claim status by author ban status - counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e2109",
   "metadata": {},
   "source": [
    "For both claims and opinions, there are many more active authors than banned authors or authors under review; however, the proportion of active authors is far greater for opinion videos than for claim videos. Again, it seems that **authors who post claim videos are more likely to come under review and/or get banned.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d3665",
   "metadata": {},
   "source": [
    "#### **Median view counts by ban status**\n",
    "\n",
    "Create a bar plot with three bars: one for each author ban status. The height of each bar should correspond with the median number of views for all videos with that author ban status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_status_counts = data.groupby(['author_ban_status']).median(\n",
    "    numeric_only=True).reset_index()\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "sns.barplot(data=ban_status_counts,\n",
    "            x='author_ban_status',\n",
    "            y='video_view_count',\n",
    "            order=['active', 'under review', 'banned'],\n",
    "            hue='author_ban_status',\n",
    "            palette='pastel',\n",
    "            alpha=0.5)\n",
    "plt.title('Median view count by ban status');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d07304",
   "metadata": {},
   "source": [
    "The median view counts for non-active authors are many times greater than the median view count for active authors. Since knowing that non-active authors are more likely to post claims, and that videos by non-active authors get far more views on aggregate than videos by active authors, then `video_view_count` might be a good indicator of claim status.\n",
    "\n",
    "Indeed, a quick check of the median view count by claim status bears out this assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('claim_status')['video_view_count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pie chart to visualize total views by claim status\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "plt.pie(data.groupby('claim_status')['video_view_count'].sum(), labels=['claim', 'opinion'])\n",
    "plt.title('Total views by video claim status');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185e1a8",
   "metadata": {},
   "source": [
    "The overall view count is dominated by claim videos even though there are roughly the same number of each video in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e702c66",
   "metadata": {},
   "source": [
    "### **Determine outliers**\n",
    "By using interquartile range (IQR), and set a threshold that is 1.5*IQR above the 3rd quartile, this method can help to inspect the outliers.\n",
    "\n",
    "In this TikTok dataset, the values for the count variables are not normally distributed. They are heavily skewed to the right. One way of modifying the outlier threshold is by calculating the **median** value for each variable and then adding 1.5 * IQR. This results in a threshold that is, in this case, much lower than it would be if you used the 3rd quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc75771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = ['video_view_count',\n",
    "              'video_like_count',\n",
    "              'video_share_count',\n",
    "              'video_download_count',\n",
    "              'video_comment_count',\n",
    "              ]\n",
    "\n",
    "for column in count_cols:\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    median = data[column].median()\n",
    "    outlier_threshold = median + 1.5*iqr\n",
    "\n",
    "    # Count the number of values that exceed the outlier threshold\n",
    "    outlier_count = (data[column] > outlier_threshold).sum()\n",
    "    print(f'Number of outliers, {column}:', outlier_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of `video_view_count` versus `video_like_count` according to 'claim_status'\n",
    "sns.scatterplot(x=data[\"video_view_count\"], y=data[\"video_like_count\"],\n",
    "                hue=data[\"claim_status\"], s=10, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of `video_view_count` versus `video_like_count` for opinions only\n",
    "opinion = data[data['claim_status']=='opinion']\n",
    "sns.scatterplot(x=opinion[\"video_view_count\"], y=opinion[\"video_like_count\"],\n",
    "                 s=10, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a93fb0",
   "metadata": {},
   "source": [
    "### **Hypothesis testing**\n",
    "To better understand the data and prepare for next step (building a regression model on verified status), I conduct a hypothesis testing to see whether or not there is a difference in views between verified and unverified accounts\n",
    "\n",
    "For the requirement of hypothesis testing, the data's collumns which are tested have to be dropped the NA value.\n",
    "\n",
    "**$H_0$**: There is no difference in number of views between TikTok videos posted by verified accounts and TikTok videos posted by unverified accounts (any observed difference in the sample data is due to chance or sampling variability).\n",
    "\n",
    "**$H_A$**: There is a difference in number of views between TikTok videos posted by verified accounts and TikTok videos posted by unverified accounts (any observed difference in the sample data is due to an actual difference in the corresponding population means).\n",
    "\n",
    "Choosing 5% as the significance level and proceed with a two-sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ea541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each sample in a variable\n",
    "not_verified = data[data[\"verified_status\"] == \"not verified\"][\"video_view_count\"]\n",
    "verified = data[data[\"verified_status\"] == \"verified\"][\"video_view_count\"]\n",
    "\n",
    "# Implement a t-test using the two samples\n",
    "stats.ttest_ind(a=not_verified, b=verified, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac181b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since the p-value is extremely small (much smaller than the significance level of 5%), reject the null hypothesis. Concluding that there **is** a statistically significant difference in the mean video view count between verified and unverified accounts on TikTok.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4716d7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "The next step will be to build a regression model on verified_status. A regression model is the natural next step because the end goal is to make predictions on claim status. A regression model for verified_status can help analyze user behavior in this group of verified users. Technical note to prepare regression model: because the data is skewed, and there is a significant difference in account types, it will be key to build a logistic regression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a824e7",
   "metadata": {},
   "source": [
    "# **Build a regression model**\n",
    "This model just show a different view from the dataset, it is not the main objective of this projec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9c8f5",
   "metadata": {},
   "source": [
    "To explore how to predict verified status to help understand how video characteristics relate to verified users. The results may be used to inform the final model related to predicting whether a video is a claim vs an opinion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c00a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and handle outliers\n",
    "\n",
    "percentile25 = data[\"video_like_count\"].quantile(0.25)\n",
    "percentile75 = data[\"video_like_count\"].quantile(0.75)\n",
    "\n",
    "iqr = percentile75 - percentile25\n",
    "upper_limit = percentile75 + 1.5 * iqr\n",
    "\n",
    "data.loc[data[\"video_like_count\"] > upper_limit, \"video_like_count\"] = upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db56a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and handle outliers\n",
    "\n",
    "percentile25 = data[\"video_comment_count\"].quantile(0.25)\n",
    "percentile75 = data[\"video_comment_count\"].quantile(0.75)\n",
    "\n",
    "iqr = percentile75 - percentile25\n",
    "upper_limit = percentile75 + 1.5 * iqr\n",
    "\n",
    "data.loc[data[\"video_comment_count\"] > upper_limit, \"video_comment_count\"] = upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "data[\"verified_status\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cf8e4",
   "metadata": {},
   "source": [
    "Approximately 93.7% of the dataset represents videos posted by unverified accounts and 6.3% represents videos posted by verified accounts. So the outcome variable is not very balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8f357",
   "metadata": {},
   "source": [
    "Use resampling to create class balance in the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use resampling to create class balance in the outcome variable\n",
    "\n",
    "# Identify data points from majority and minority classes\n",
    "data_majority = data[data[\"verified_status\"] == \"not verified\"]\n",
    "data_minority = data[data[\"verified_status\"] == \"verified\"]\n",
    "\n",
    "# Upsample the minority class (which is \"verified\")\n",
    "data_minority_upsampled = resample(data_minority,\n",
    "                                 replace=True,                 \n",
    "                                 n_samples=len(data_majority), \n",
    "                                 random_state=0)               \n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled]).reset_index(drop=True)\n",
    "\n",
    "# Display new class counts\n",
    "data_upsampled[\"verified_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average `video_transcription_text` length for verified accounts and the average `video_transcription_text` length for unverified accounts\n",
    "data_upsampled[[\"verified_status\", \"video_transcription_text\"]].groupby(by=\"verified_status\")[[\"video_transcription_text\"]].agg(func=lambda array: np.mean([len(text) for text in array]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16927376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the length of each `video_transcription_text` and add this as a column to the dataframe\n",
    "data_upsampled[\"text_length\"] = data_upsampled[\"video_transcription_text\"].apply(func=lambda text: len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb193d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of dataframe after adding new column\n",
    "data_upsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of `video_transcription_text` length for videos posted by verified accounts and videos posted by unverified accounts\n",
    "# Create two histograms in one plot\n",
    "sns.histplot(data=data_upsampled, stat=\"count\", multiple=\"stack\", x=\"text_length\", kde=False, palette=\"pastel\", \n",
    "             hue=\"verified_status\", element=\"bars\", legend=True)\n",
    "plt.title(\"Seaborn Stacked Histogram\")\n",
    "plt.xlabel(\"video_transcription_text length (number of characters)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of video_transcription_text length for videos posted by verified accounts and videos posted by unverified accounts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a7d83",
   "metadata": {},
   "source": [
    "### **Examine correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code a correlation matrix to help determine most correlated variables\n",
    "data_upsampled.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14264df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap to visualize how correlated variables are\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    data_upsampled[[\"video_duration_sec\", \"claim_status\", \"author_ban_status\", \"video_view_count\", \n",
    "                    \"video_like_count\", \"video_share_count\", \"video_download_count\", \"video_comment_count\", \"text_length\"]]\n",
    "    .corr(numeric_only=True), \n",
    "    annot=True, \n",
    "    cmap=\"crest\")\n",
    "plt.title(\"Heatmap of the dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab251cc8",
   "metadata": {},
   "source": [
    "The above heatmap shows that the following pair of variables are strongly correlated: `video_view_count` and `video_like_count` (0.86 correlation coefficient).\n",
    "\n",
    "One of the model assumptions for logistic regression is no severe multicollinearity among the features. To build a logistic regression model that meets this assumption, you could exclude `video_like_count`. And among the variables that quantify video metrics, you could keep `video_view_count`, `video_share_count`, `video_download_count`, and `video_comment_count` as features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de09dfa",
   "metadata": {},
   "source": [
    "### **Select variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41859300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select outcome variable\n",
    "y = data_upsampled[\"verified_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X = data_upsampled[[\"video_duration_sec\", \"claim_status\", \"author_ban_status\", \"video_view_count\", \"video_share_count\", \"video_download_count\", \"video_comment_count\"]]\n",
    "\n",
    "# Display first few rows of features dataframe\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aaf101",
   "metadata": {},
   "source": [
    "### **Train-test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1955bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shape of each training and testing set\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54a2a5",
   "metadata": {},
   "source": [
    "### **Encode variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28239dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in `claim_status`\n",
    "X_train[\"claim_status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in `author_ban_status`\n",
    "X_train[\"author_ban_status\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba909946",
   "metadata": {},
   "source": [
    "Encode categorical features in the training set using an appropriate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacae2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training features that needs to be encoded\n",
    "X_train_to_encode = X_train[[\"claim_status\", \"author_ban_status\"]]\n",
    "\n",
    "# Display first few rows\n",
    "X_train_to_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abfaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an encoder for one-hot encoding the categorical features\n",
    "X_encoder = OneHotEncoder(drop='first', sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training features using the encoder\n",
    "X_train_encoded = X_encoder.fit_transform(X_train_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb615ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from encoder\n",
    "X_encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d21b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of encoded training features\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place encoded training features (which is currently an array) into a dataframe\n",
    "X_train_encoded_df = pd.DataFrame(data=X_train_encoded, columns=X_encoder.get_feature_names_out())\n",
    "\n",
    "# Display first few rows\n",
    "X_train_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Concatenate `X_train` and `X_train_encoded_df` to form the final dataframe for training data (`X_train_final`)\n",
    "# so that the indices align with those in `X_train_encoded_df` and `count_df`\n",
    "X_train_final = pd.concat([X_train.drop(columns=[\"claim_status\", \"author_ban_status\"]).reset_index(drop=True), X_train_encoded_df], axis=1)\n",
    "\n",
    "# Display first few rows\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of outcome variable\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type of outcome variable\n",
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ede3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an encoder for one-hot encoding the categorical outcome variable\n",
    "y_encoder = OneHotEncoder(drop='first', sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d536c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the training outcome variable\n",
    "# Notes:\n",
    "#   - Adjusting the shape of `y_train` before passing into `.fit_transform()`, since it takes in 2D array\n",
    "#   - Using `.ravel()` to flatten the array returned by `.fit_transform()`, so that it can be used later to train the model\n",
    "y_train_final = y_encoder.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Display the encoded training outcome variable\n",
    "y_train_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75a733",
   "metadata": {},
   "source": [
    "### **Model building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a logistic regression model and fit it to the training set\n",
    "log_clf = LogisticRegression(random_state=0, max_iter=800).fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ac6d9",
   "metadata": {},
   "source": [
    "### **Results and evaluation**\n",
    "\n",
    "Evaluate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the testing features that needs to be encoded\n",
    "X_test_to_encode = X_test[[\"claim_status\", \"author_ban_status\"]]\n",
    "\n",
    "# Display first few rows\n",
    "X_test_to_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the testing features using the encoder\n",
    "X_test_encoded = X_encoder.transform(X_test_to_encode)\n",
    "\n",
    "# Place encoded testing features (which is currently an array) into a dataframe\n",
    "X_test_encoded_df = pd.DataFrame(data=X_test_encoded, columns=X_encoder.get_feature_names_out())\n",
    "\n",
    "X_test.drop(columns=[\"claim_status\", \"author_ban_status\"]).head()\n",
    "X_test_final = pd.concat([X_test.drop(columns=[\"claim_status\", \"author_ban_status\"]).reset_index(drop=True), X_test_encoded_df], axis=1)\n",
    "\n",
    "# Display first few rows\n",
    "X_test_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the logistic regression model to get predictions on the encoded testing set\n",
    "y_pred = log_clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa9f14",
   "metadata": {},
   "source": [
    "Encode the true labels of the testing set so it can be compared to the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final = y_encoder.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Display the encoded testing outcome variable\n",
    "y_test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170230e0",
   "metadata": {},
   "source": [
    "### **Visualize model results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute values for confusion matrix\n",
    "log_cm = confusion_matrix(y_test_final, y_pred, labels=log_clf.classes_)\n",
    "\n",
    "# Create display of confusion matrix\n",
    "log_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=log_clf.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "log_disp.plot()\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report for logistic regression model\n",
    "target_labels = [\"verified\", \"not verified\"]\n",
    "print(classification_report(y_test_final, y_pred, target_names=target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aceb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names from the model and the model coefficients (which represent log-odds ratios)\n",
    "# Place into a DataFrame for readability\n",
    "pd.DataFrame(data={\"Feature Name\":log_clf.feature_names_in_, \"Model Coefficient\":log_clf.coef_[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da3971",
   "metadata": {},
   "source": [
    "We developed a logistic regression model for verified status based on video features. The model had decent predictive power. Based on the estimated model coefficients from the logistic regression, longer videos tend to be associated with higher odds of the user being verified. Other video features have small estimated coefficients in the model, so their association with verified status seems to be small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b99149",
   "metadata": {},
   "source": [
    "# **Classifying videos using machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e4ef1",
   "metadata": {},
   "source": [
    "It's more important to minimize false negatives, the model evaluation metric will be **recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d441ebcb",
   "metadata": {},
   "source": [
    "**Modeling workflow and model selection process**\n",
    "\n",
    "Previous work with this data has revealed that there are ~20,000 videos in the sample. This is sufficient to conduct a rigorous model validation workflow, broken into the following steps:\n",
    "\n",
    "1. Split the data into train/validation/test sets (60/20/20)\n",
    "2. Fit models and tune hyperparameters on the training set\n",
    "3. Perform final model selection on the validation set\n",
    "4. Assess the champion model's performance on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a964c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe data2 that drops the likes_per_view, comments_per_view, shares_per_view columns\n",
    "data2 = data.drop(['likes_per_view', 'comments_per_view', 'shares_per_view'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "data2[\"claim_status\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a098e7",
   "metadata": {},
   "source": [
    "Approximately 50.3% of the dataset represents claims and 49.7% represents opinions, so the outcome variable is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39a25b",
   "metadata": {},
   "source": [
    "### **Feature engineering**\n",
    "\n",
    "\n",
    "Extract the length (character count) of each `video_transcription_text` and add this to the dataframe as a new column called `text_length` so that it can be used as a feature in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accef5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['text_length'] = data2['video_transcription_text'].str.len()\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c54c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average text length for each claim status\n",
    "data2[['claim_status', 'text_length']].groupby('claim_status').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of `text_length` for claims and opinions\n",
    "# Create two histograms in one plot\n",
    "\n",
    "sns.histplot(data=data2, stat=\"count\", multiple=\"dodge\", x=\"text_length\",\n",
    "             kde=False, palette=\"pastel\", hue=\"claim_status\",\n",
    "             element=\"bars\", legend=True)\n",
    "plt.xlabel(\"video_transcription_text length (number of characters)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of video_transcription_text length for claims and opinions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1cca4",
   "metadata": {},
   "source": [
    "Letter count distributions for both claims and opinions are approximately normal with a slight right skew. Claim videos tend to have more characters&mdash;about 13 more on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de1488",
   "metadata": {},
   "source": [
    "**Feature selection and transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad708097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode target variable and dummy encode categorical features\n",
    "# encode the data to X2 and y2 since the previous X and y have been used for logistic regression\n",
    "X2 = data2.copy()\n",
    "# Drop unnecessary columns\n",
    "X2 = X2.drop(['#', 'video_id'], axis=1)\n",
    "# Encode target variable\n",
    "X2['claim_status'] = X2['claim_status'].replace({'opinion': 0, 'claim': 1})\n",
    "# Dummy encode remaining categorical values\n",
    "X2 = pd.get_dummies(X2,\n",
    "                   columns=['verified_status', 'author_ban_status'],\n",
    "                   drop_first=True)\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7d5c7",
   "metadata": {},
   "source": [
    "### **Split the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate target variable\n",
    "y2 = X2['claim_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate features\n",
    "X2 = X2.drop(['claim_status'], axis=1)\n",
    "\n",
    "# Display first few rows of features dataframe\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a34eb0",
   "metadata": {},
   "source": [
    "#### **Create train/validate/test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X2, y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12915731",
   "metadata": {},
   "source": [
    "Confirm that the dimensions of the training, validation, and testing sets are in alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shape of each training, validation, and testing set\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a `CountVectorizer` object, which converts a collection of text to a matrix of token counts\n",
    "count_vec = CountVectorizer(ngram_range=(2, 3),\n",
    "                            max_features=15,\n",
    "                            stop_words='english')\n",
    "count_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2497916",
   "metadata": {},
   "source": [
    "Fit the vectorizer to the training data (generate the n-grams) and transform it (tally the occurrences). Only fit to the training data, not the validation or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical features from `video_transcription_text` in the training set\n",
    "count_data = count_vec.fit_transform(X_train['video_transcription_text']).toarray()\n",
    "count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the numerical representation of `video_transcription_text` from training set into a dataframe\n",
    "count_df = pd.DataFrame(data=count_data, columns=count_vec.get_feature_names_out())\n",
    "\n",
    "# Display first few rows\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d31d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate `X_train` and `count_df` to form the final dataframe for training data (`X_train_final`)\n",
    "X_train_final = pd.concat([X_train.drop(columns=['video_transcription_text']).reset_index(drop=True), count_df], axis=1)\n",
    "\n",
    "# Display first few rows\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical features from `video_transcription_text` in the testing set\n",
    "validation_count_data = count_vec.transform(X_val['video_transcription_text']).toarray()\n",
    "validation_count_data\n",
    "# the validation set is not being fit, just transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dfc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the numerical representation of `video_transcription_text` from validation set into a dataframe\n",
    "validation_count_df = pd.DataFrame(data=validation_count_data, columns=count_vec.get_feature_names_out())\n",
    "validation_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate `X_val` and `validation_count_df` to form the final dataframe for training data (`X_val_final`)\n",
    "X_val_final = pd.concat([X_val.drop(columns=['video_transcription_text']).reset_index(drop=True), validation_count_df], axis=1)\n",
    "\n",
    "# Display first few rows\n",
    "X_val_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb4fe7",
   "metadata": {},
   "source": [
    "Repeat the process to get n-gram counts for the test data. Again, don't refit the vectorizer to the test data. Just transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0cc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical features from `video_transcription_text` in the testing set\n",
    "test_count_data = count_vec.transform(X_test['video_transcription_text']).toarray()\n",
    "\n",
    "# Place the numerical representation of `video_transcription_text` from test set into a dataframe\n",
    "test_count_df = pd.DataFrame(data=test_count_data, columns=count_vec.get_feature_names_out())\n",
    "\n",
    "# Concatenate `X_val` and `validation_count_df` to form the final dataframe for training data (`X_val_final`)\n",
    "X_test_final = pd.concat([X_test.drop(columns=['video_transcription_text']\n",
    "                                      ).reset_index(drop=True), test_count_df], axis=1)\n",
    "X_test_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64986d80",
   "metadata": {},
   "source": [
    "### **Build models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f49cf",
   "metadata": {},
   "source": [
    "### **Build a random forest model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa397129",
   "metadata": {},
   "source": [
    "Fit a random forest model to the training set. Use cross-validation to tune the hyperparameters and select the model that performs best on recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [5, 7, None],\n",
    "             'max_features': [0.3, 0.6],\n",
    "            #  'max_features': 'auto'\n",
    "             'max_samples': [0.7],\n",
    "             'min_samples_leaf': [1,2],\n",
    "             'min_samples_split': [2,3],\n",
    "             'n_estimators': [75,100,200],\n",
    "             }\n",
    "\n",
    "# Define a list of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "rf_cv = GridSearchCV(rf, cv_params, scoring=scoring, cv=5, refit='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_cv.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine best recall score\n",
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine best parameters\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938b970",
   "metadata": {},
   "source": [
    "Check the precision score to make sure the model isn't labeling everything as claims. You can do this by using the `cv_results_` attribute of the fit `GridSearchCV` object, which returns a numpy array that can be converted to a pandas dataframe. Then, examine the `mean_test_precision` column of this dataframe at the index containing the results from the best model. This index can be accessed by using the `best_index_` attribute of the fit `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the GridSearch results and convert it to a pandas df\n",
    "rf_results_df = pd.DataFrame(rf_cv.cv_results_)\n",
    "\n",
    "# Examine the GridSearch results df at column `mean_test_precision` in the best index\n",
    "rf_results_df['mean_test_precision'][rf_cv.best_index_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bcfd89",
   "metadata": {},
   "source": [
    "\n",
    "This model performs exceptionally well, with an average recall score of 0.995 across the five cross-validation folds. After checking the precision score to be sure the model is not classifying all samples as claims, it is clear that this model is making almost perfect classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4418b1f",
   "metadata": {},
   "source": [
    "### **Build an XGBoost model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68de0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=0)\n",
    "\n",
    "# Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'max_depth': [4,8,12],\n",
    "             'min_child_weight': [3, 5],\n",
    "             'learning_rate': [0.01, 0.1],\n",
    "             'n_estimators': [300, 500]\n",
    "             }\n",
    "\n",
    "# Define a list of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "xgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=5, refit='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_cv.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236eaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35952795",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abf722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the GridSearch results and convert it to a pandas df\n",
    "xgb_results_df = pd.DataFrame(xgb_cv.cv_results_)\n",
    "\n",
    "# Examine the GridSearch results df at column `mean_test_precision` in the best index\n",
    "xgb_results_df['mean_test_precision'][xgb_cv.best_index_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5898f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This model also performs exceptionally well. Although both its precision and recall scores are very slightly lower than the random forest model's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4015894",
   "metadata": {},
   "source": [
    "### **Task 7. Evaluate models**\n",
    "\n",
    "Evaluate models against validation data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da927840",
   "metadata": {},
   "source": [
    "#### **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random forest \"best estimator\" model to get predictions on the validation set\n",
    "y_pred = rf_cv.best_estimator_.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the predictions on the validation set\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the true labels of the validation set\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix to visualize the results of the classification model\n",
    "\n",
    "# Compute values for confusion matrix\n",
    "log_cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Create display of confusion matrix\n",
    "log_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n",
    "\n",
    "# Plot confusion matrix\n",
    "log_disp.plot()\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report for random forest model\n",
    "target_labels = ['opinion', 'claim']\n",
    "print(classification_report(y_val, y_pred, target_names=target_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b982d",
   "metadata": {},
   "source": [
    "#### **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to predict on the validation data\n",
    "y_pred = xgb_cv.best_estimator_.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute values for confusion matrix\n",
    "log_cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Create display of confusion matrix\n",
    "log_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n",
    "\n",
    "# Plot confusion matrix\n",
    "log_disp.plot()\n",
    "\n",
    "# Display plot\n",
    "plt.title('XGBoost - validation set');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification report\n",
    "target_labels = ['opinion', 'claim']\n",
    "print(classification_report(y_val, y_pred, target_names=target_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afd6f36",
   "metadata": {},
   "source": [
    "The results of the XGBoost model were also nearly perfect. However, its errors tended to be false negatives.Which means there are more actual claims that are classified as opinions, it costs more for the company. The random forest model has a better scores, and is therefore the champion model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6926d2",
   "metadata": {},
   "source": [
    "### **Use champion model to predict on test data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f009ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use champion model to predict on test data\n",
    "y_pred = rf_cv.best_estimator_.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute values for confusion matrix\n",
    "log_cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create display of confusion matrix\n",
    "log_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n",
    "\n",
    "# Plot confusion matrix\n",
    "log_disp.plot()\n",
    "\n",
    "# Display plot\n",
    "plt.title('Random forest - test set');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43b45e",
   "metadata": {},
   "source": [
    "#### **Feature importances of champion model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278edb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_cv.best_estimator_.feature_importances_\n",
    "rf_importances = pd.Series(importances, index=X_test_final.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rf_importances.plot.bar(ax=ax)\n",
    "ax.set_title('Feature importances')\n",
    "ax.set_ylabel('Mean decrease in impurity')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3d1f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The most predictive features all were related to engagement levels generated by the video. This is not unexpected, as analysis from prior EDA pointed to this conclusion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
