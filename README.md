# TikTok Claim vs Opinion Detection (Data Analyst Intern Project)

> **Oneâ€‘liner:** Classify TikTok texts as **Claim vs Opinion** to prioritize factâ€‘checking and cut manual moderation time.

## Table of Contents
- [TL;DR](#tldr)
- [Business Problem](#business-problem)
- [Data](#data)
- [Methodology](#methodology)
- [Results](#results)
- [Reproducibility](#reproducibility)
- [Project Structure](#project-structure)
- [Limitations & Ethics](#limitations--ethics)
- [Next Steps](#next-steps)
- [Credits](#credits)

## TL;DR
- **Data:** N = 19084 videos (text + creator/account metadata).
- **Methods:** nâ€‘gram text features + classic ML (logistic baseline) with holdâ€‘out test.
- **KPI:** prioritize **Recall(Claim)** with balanced F1.
- **Result:** **Accuracy = 0.99** on test; **F1 (Claim) = 0.99**, **Recall (Claim) = 0.99**.

## Business Problem
Moderation teams need to **catch claims early** to route factâ€‘checking. Missing a claim is costly (escalations, misinformation risk).  
**Objective:** maximize **Recall(Claim)** while keeping overall F1 balanced for stable operations.

## Data
- **Path:** `data/tiktok_dataset.csv` (not committed; use a small sample if needed)  
- **Shape:** 19084 rows Ã— 12 columns (see schema).  
- **Target:** `claim_status` âˆˆ {`claim`, `opinion`}.  
- **Test set:** 3817 rows; class counts â€” claim: 1925, opinion: 1892 (â‰ˆ 50/50).

### Schema (abridged)
| Column | Dtype | Description |
|---|---|---|
| `#` | `int64` | row index from source |
| `claim_status` | `object` | ground truth label: 'claim' or 'opinion' |
| `video_id` | `int64` | unique video identifier |
| `video_duration_sec` | `int64` | video length in seconds |
| `video_transcription_text` | `object` | ASR text |
| `verified_status` | `object` | account verification flag |
| `author_ban_status` | `object` | creator ban status |
| `video_view_count` | `float64` | views |
| `video_like_count` | `float64` | likes |
| `video_share_count` | `float64` | shares |
| `video_download_count` | `float64` | downloads |
| `video_comment_count` | `float64` | comments |

**Privacy:** texts are anonymized; no PII is committed to this repo.

## Methodology
1. **EDA:** label balance; text length distributions; slices by verified_status and author_ban_status.  
2. **Preprocessing:**  
   - Vectorization: CountVectorizer / TfidfVectorizer on video_transcription_text with n-grams (2â€“3) and English stopwords.
   - Categoricals: encoded via pd.get_dummies(...) (khÃ´ng dÃ¹ng ColumnTransformer).
   - Oneâ€‘hot encode selected categorical fields (e.g., `author_ban_status`); numeric features standardized if used.  
3. **Modeling:** XG Boost and Random Forest model, the final model is Random Forest model.  
4. **Validation:** hold-out split test; fixed `random_state` for reproducibility.  
5. **Evaluation:** classification_report (precision/recall/F1 per class), Recall(Claim) as the primary KPI, plus overall accuracy and confusion_matrix.

## Results
| Metric | Value |
|---|---|
| Accuracy (test) | 1.00 |
| F1 â€” Claim | 1.00 |
| Recall â€” Claim | 1.00 |
| Precision â€” Claim | 1.00 |
| F1 â€” Opinion | 1.00 |


Figure for random forest model:
![Confusion Matrix](images/confusion_matrix.png)

![Feaure importances](images/feature_importances.png)

## Reproducibility
```bash
# 1) Create env
python -m venv .venv && source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# 2) Run the notebook (interactive)
# open project.ipynb and run all cells

You can explore the full notebook output without running the code or Github can not run the code block:

ðŸ‘‰ [View Full Report (HTML)](https://bumbumlinh91.github.io/tiktok-project/claim-opinion.html)
```

**Data expectation:** place a CSV at `data/tiktok_dataset.csv` with at least the schema above.  
**Determinism:** set `random_state=0` (already in the notebook).

## Project Structure
```
tiktok-project/
â”‚
â”œâ”€â”€ data/ # Dataset used in the project
â”‚ â””â”€â”€ tiktok_dataset.csv
â”‚
â”œâ”€â”€ docs/ # Documentation & exported reports
â”‚ â””â”€â”€ project.html
â”‚
â”œâ”€â”€ images/ # Figures generated by the analysis
â”‚ â”œâ”€â”€ confusion_matrix.png
â”‚ â”œâ”€â”€ feature_importances.png
â”‚
â”œâ”€â”€ project.ipynb # Main Jupyter notebook
â””â”€â”€ requirements.txt # Project dependencies
```

## Limitations & Ethics
- **Textâ€‘only**: no audio/video cues â€” some context is lost.
- **Domain drift**: language on TikTok changes fast; retrain periodically.
- **Bias**: author metadata can encode demographic/behavioral bias â€” audit before production.

## Next Steps
- Replace nâ€‘gram counts with lightweight transformer embeddings + distillation.
- Active learning loop to mine **hard negatives** (borderline opinions).
- Reviewer dashboard (Streamlit) to inspect predictions and false negatives.

## Credits
Built by **Linh** â€” Data Analyst (Intern) candidate. Dataset: TikTok text + public engagement fields.
